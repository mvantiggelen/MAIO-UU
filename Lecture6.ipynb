{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open the data from your own stations in the Botanical gardens\n",
    "2. Merge all files in a single dataframe\n",
    "3. Compute hourly averages\n",
    "4. Write variable attributes\n",
    "5. Export to netCDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python packages\n",
    "import os\n",
    "import glob as glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "# custom packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the location of current folder \n",
    "base_dir = os.getcwd()\n",
    "print(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to the folder with raw data from MAIO setup\n",
    "L0_folder = base_dir + \"/Data/UU_BotanicalGardens/L0/\"\n",
    "os.chdir(L0_folder)\n",
    "\n",
    "# List all the data files\n",
    "files = glob.glob('*txt')\n",
    "print('input files: ', files)\n",
    "\n",
    "# open each file and merge in same dataframe\n",
    "for idx, file in enumerate(files):\n",
    "    # open CSV file\n",
    "    df = pd.read_csv(file,delimiter = ',', na_values = -999,header=0)\n",
    "    # Rename time variable\n",
    "    df.rename(columns={'Time(UTC)': 'time'}, inplace=True)\n",
    "    # Set time variable as dataframe index\n",
    "    df = df.set_index('time')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    if idx == 0:\n",
    "        df_out = df\n",
    "    else:\n",
    "        # merge dataframes\n",
    "        df_out = df_out.join(df, how='outer')\n",
    "\n",
    "# list variables\n",
    "print('variables: ', df_out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make xarray dataset from pandas dataframe\n",
    "ds = df_out.to_xarray()\n",
    "# Compute hourly averages\n",
    "ds_hour = ds.resample(time=\"1H\",label = 'left').mean()\n",
    "\n",
    "\n",
    "ds_hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset to net CDF in new folder\n",
    "L1_folder  = base_dir + \"/Data/UU_BotanicalGardens/L1/\"\n",
    "\n",
    "name = 'MAIO'\n",
    "year = '2023'\n",
    "loc = 'BG'\n",
    "version = '1.0'\n",
    "level = 'L1'\n",
    "period = '1H'\n",
    "oformat = 'nc'\n",
    "file_out = f'{L1_folder}{name}_{year}_{loc}_{level}_{period}_{version}.{oformat}'\n",
    "\n",
    "# Read metadata file\n",
    "meta_file = base_dir + '/Metadata/variables.csv'\n",
    "meta = pd.read_csv(meta_file, index_col=0, comment=\"#\")\n",
    "\n",
    "# Write metadata for each variable in output file\n",
    "for var in list(ds_hour.variables):\n",
    "     for attr in list(meta.keys()):\n",
    "          if len(meta[meta.index==var][attr].values) > 0:\n",
    "               ds_hour[var].attrs[attr] = meta[meta.index==var][attr].values[0]\n",
    "     \n",
    "# add some general attributes\n",
    "ds_hour.attrs['file_creation_date_time']     = str(datetime.datetime.now())\n",
    "\n",
    "# create output folder\n",
    "if not os.path.exists(L1_folder):\n",
    "     os.makedirs(L1_folder) \n",
    "os.chdir(L1_folder)\n",
    "\n",
    "# Export to net CDF\n",
    "ds_hour.to_netcdf(file_out,mode = 'w')\n",
    "\n",
    "# go back to main folder\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will download data from the KNMI AWS in de Bilt :\n",
    "- Go to https://daggegevens.knmi.nl/klimatologie/uurgegevens\n",
    "- Select all parameters ('Velden'), station de Bilt, all data since 20230901 in csv format (see screenshot below)\n",
    "- save data to a new 'L0' folder in the 'KNMI_deBilt' folder \n",
    "\n",
    "![Alt text](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open KNMI data\n",
    "# Move to the folder with raw data from KNMI website \n",
    "L0_folder = base_dir + \"/Data/KNMI_deBilt/L0/\"\n",
    "os.chdir(L0_folder)\n",
    "\n",
    "# List all the data files\n",
    "files = glob.glob('*txt') # change this if you have .csv files\n",
    "print('input files: ', files)\n",
    "\n",
    "# Standard variables \n",
    "column_names = ['STN','YYYYMMDD','H',   'DD',   'FH',   'FF',   'FX',    'T', 'T10N',   'TD',   'SQ',    'Q',   'DR',   'RH',    'P',   'VV',    'N',    'U',   'WW',   'IX',    'M',    'R',    'S',    'O',    'Y']\n",
    "\n",
    "# open each file and merge in same dataframe\n",
    "for idx, file in enumerate(files):\n",
    "    # open CSV file\n",
    "    \n",
    "    df = pd.read_csv(file,delimiter = ',', skiprows=30,names=column_names)\n",
    "    # Rename time variable\n",
    "    # df.rename(columns={'Time(UTC)': 'time'}, inplace=True)\n",
    "    # Set time variable as dataframe index\n",
    "    # df = df.set_index('time')\n",
    "    # df.index = pd.to_datetime(df.index)\n",
    "    if idx == 0:\n",
    "        df_out = df\n",
    "    else:\n",
    "        # merge dataframes\n",
    "        df_out = df_out.join(df, how='outer')\n",
    "\n",
    "# Make time index\n",
    "df_out['time'] = pd.to_datetime(df_out['YYYYMMDD'], format='%Y%m%d') + pd.to_timedelta(df_out[\"H\"], unit=\"H\")\n",
    "df_out  = df_out.set_index('time')\n",
    "# list variables\n",
    "print('variables: ', df_out.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert variables\n",
    "df_out['FH'] = df_out['FH']*0.1\n",
    "df_out['FF'] = df_out['FF']*0.1\n",
    "df_out['FX'] = df_out['FX']*0.1\n",
    "df_out['T'] = df_out['T']*0.1\n",
    "df_out['TD'] = df_out['TD']*0.1\n",
    "df_out['P'] = df_out['P']*0.1\n",
    "\n",
    "# Keep variables of interest\n",
    "colums_out = ['FH','FF','FX','T','TD','P']\n",
    "df_out = df_out[colums_out]\n",
    "\n",
    "# convnert to xarray dataset\n",
    "ds = df_out.to_xarray()\n",
    "\n",
    "# Export dataset to net CDF in new folder\n",
    "L1_folder  = base_dir + \"/Data/KNMI_deBilt/L1/\"\n",
    "\n",
    "name = 'KNMI_AWS'\n",
    "year = '2023'\n",
    "loc = 'deBilt'\n",
    "version = '1.0'\n",
    "level = 'L1'\n",
    "period = '1H'\n",
    "oformat = 'nc'\n",
    "file_out = f'{L1_folder}{name}_{year}_{loc}_{level}_{period}_{version}.{oformat}'\n",
    "\n",
    "# add some general attributes\n",
    "ds.attrs['file_creation_date_time']     = str(datetime.datetime.now())\n",
    "\n",
    "# create output folder\n",
    "if not os.path.exists(L1_folder):\n",
    "     os.makedirs(L1_folder) \n",
    "os.chdir(L1_folder)\n",
    "\n",
    "# Export to net CDF\n",
    "ds.to_netcdf(file_out,mode = 'w')\n",
    "\n",
    "# go back to main folder\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to compare the KNMI data to our own data.\n",
    "- Open the L1 file with MAIO data\n",
    "- Open the L1 cile from KNMI data\n",
    "- Merge variables from both datasets in a new dataset\n",
    "- make some scatter plots & timeseries plots\n",
    "- save plots and data to a new L2 folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIO_folder = base_dir + \"/Data/UU_BotanicalGardens/L1/\"\n",
    "KNMI_folder  = base_dir + \"/Data/KNMI_deBilt/L1/\"\n",
    "\n",
    "# Open file with MAIO data\n",
    "os.chdir(MAIO_folder)\n",
    "file = glob.glob('*nc')\n",
    "ds_1 = xr.open_dataset(file[0],engine='scipy')\n",
    "# Open file with KNMI data\n",
    "os.chdir(KNMI_folder)\n",
    "file = glob.glob('*nc')\n",
    "ds_2 = xr.open_dataset(file[0],engine='scipy')\n",
    "\n",
    "# Merge dataset\n",
    "ds_out = xr.merge([ds_1,ds_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset to net CDF in new folder\n",
    "L2_folder  = base_dir + \"/Data/UU_BotanicalGardens/L2/\"\n",
    "\n",
    "name = 'MAIO'\n",
    "year = '2023'\n",
    "loc = 'BT'\n",
    "version = '1.0'\n",
    "level = 'L2'\n",
    "period = '1H'\n",
    "oformat = 'nc'\n",
    "file_out = f'{L2_folder}{name}_{year}_{loc}_{level}_{period}_{version}.{oformat}'\n",
    "\n",
    "# add some general attributes\n",
    "ds_out.attrs['file_creation_date_time']     = str(datetime.datetime.now())\n",
    "\n",
    "# create output folder\n",
    "if not os.path.exists(L2_folder):\n",
    "     os.makedirs(L2_folder) \n",
    "os.chdir(L2_folder)\n",
    "\n",
    "# Export to net CDF\n",
    "ds_out.to_netcdf(file_out,mode = 'w')\n",
    "\n",
    "# go back to main folder\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scatter plot between 2 variables\n",
    "os.chdir(L2_folder)\n",
    "\n",
    "xvar = \"T\" #T\n",
    "yvar = \"t_1\" #t_0\n",
    "min = np.nanmin([np.min(ds_out[xvar]).values,np.nanmin(ds_out[yvar].values)])\n",
    "max = np.nanmax([np.max(ds_out[xvar]).values,np.nanmax(ds_out[yvar].values)])\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.axline((min, min), (max, max), linewidth=1, color='k')\n",
    "ds_out.plot.scatter(x=xvar, y=yvar)\n",
    "plt.xlim([min,max])\n",
    "plt.ylim([min,max])\n",
    "plt.tight_layout()\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.savefig('scatter_%s.png'%(xvar + yvar))\n",
    "plt.show()\n",
    "\n",
    "# COmpute bias and RMSE\n",
    "bias = np.nanmean(ds_out[yvar] - ds_out[xvar])\n",
    "RMS = np.sqrt(np.nanmean((ds_out[yvar] - ds_out[xvar])**2))\n",
    "\n",
    "print('bias = ',bias)\n",
    "print('RMS = ',RMS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a time series plot of 5 variables\n",
    "os.chdir(L2_folder)\n",
    "\n",
    "yvar_1 = \"t_0\"\n",
    "yvar_2 = \"T\"\n",
    "yvar_3 = \"Tc2\"\n",
    "yvar_4 = \"Ts\"\n",
    "yvar_5 = \"t_1\"\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ds_out[yvar_1].plot.line()\n",
    "ds_out[yvar_2].plot.line()\n",
    "ds_out[yvar_3].plot.line()\n",
    "ds_out[yvar_4].plot.line()\n",
    "ds_out[yvar_5].plot.line()\n",
    "\n",
    "plt.xlim(pd.Timestamp('2023-09-22'), pd.Timestamp('2023-10-03'))\n",
    "plt.tight_layout()\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.legend([yvar_1, yvar_2, yvar_3, yvar_4, yvar_5])\n",
    "\n",
    "plt.savefig('timeseries_%s.png'%(yvar_1 + yvar_2 + yvar_3 + yvar_4 + yvar_5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
